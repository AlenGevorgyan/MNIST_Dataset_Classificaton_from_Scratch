# ðŸ”¢ MNIST Classification From Scratch

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![NumPy](https://img.shields.io/badge/Library-NumPy-lightgrey?logo=numpy)](https://numpy.org/)

A deep dive into the mathematics of Machine Learning. This project implements a **Multilayer Perceptron (MLP)** from the ground up using only linear algebra, without the help of high-level frameworks like TensorFlow or PyTorch.



## ðŸ§  Core Objectives
* **Manual Backpropagation**: Implementing the chain rule for weight updates.
* **Matrix Calculus**: Leveraging vectorized operations for efficiency.
* **Activation Functions**: Manual implementation of ReLU (Hidden) and Softmax (Output).

---

## ðŸš€ Quick Start

### 1. Clone & Install
```bash
git clone [https://github.com/your-username/mnist-scratch.git](https://github.com/AlenGevorgyan/MNIST_Dataset_Classificaton_from_Scratch.git)
cd MNIST_Dataset_Classificaton_from_Scratch
```
And run all cells
